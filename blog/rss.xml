<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>Amin Saied Blog</title>
        <link>https://aminsaied.github.io/blog</link>
        <description>Amin Saied Blog</description>
        <lastBuildDate>Fri, 24 Sep 2021 00:00:00 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[âœ¨Talk: Roberta and Electra]]></title>
            <link>https://aminsaied.github.io/blog/2021/09/24/roberta-electra</link>
            <guid>/2021/09/24/roberta-electra</guid>
            <pubDate>Fri, 24 Sep 2021 00:00:00 GMT</pubDate>
            <description><![CDATA[Abstract. In this talk I give an overview of two important transformer]]></description>
            <content:encoded><![CDATA[<p><strong>Abstract.</strong> In this talk I give an overview of two important transformer
models in NLP.</p><p>ðŸ˜´ Lazy blog - just a link to the talk's <a target="_blank" href="/assets/files/2021-09-24-deck-bfb6e465f155ab11a614dde36513e512.pdf">ðŸ“‹PDF</a>.</p>]]></content:encoded>
            <category>talk</category>
            <category>nlp</category>
        </item>
        <item>
            <title><![CDATA[âœ¨Talk: Graph Neural Networks]]></title>
            <link>https://aminsaied.github.io/blog/2021/08/19/gnns</link>
            <guid>/2021/08/19/gnns</guid>
            <pubDate>Thu, 19 Aug 2021 00:00:00 GMT</pubDate>
            <description><![CDATA[Abstract. A gentle introduction to graph neural networks (GNN)s]]></description>
            <content:encoded><![CDATA[<p><strong>Abstract.</strong> A gentle introduction to graph neural networks (GNN)s</p><ul><li>Attention mechanisms in GNNs</li><li>PyTorch Geometric example: Karate Dataset</li><li>This will be an introductory talk with lots of pictures (in fact, it
will almost exclusively be pictures!)</li></ul><p>ðŸ˜´ Lazy blog - just a link to the talk's <a target="_blank" href="/assets/files/2021-08-19-deck-a2df5fa6372f69d07cc422f3c7800d37.pdf">ðŸ“‹PDF</a>.</p>]]></content:encoded>
            <category>talk</category>
            <category>gnn</category>
            <category>intro</category>
        </item>
        <item>
            <title><![CDATA[âœ¨Talk: Introduction to PyTorch Lightning]]></title>
            <link>https://aminsaied.github.io/blog/2021/05/07/pytorch-lightning</link>
            <guid>/2021/05/07/pytorch-lightning</guid>
            <pubDate>Fri, 07 May 2021 00:00:00 GMT</pubDate>
            <description><![CDATA[Abstract. A hands on guide to using PyTorch Lightning. Concretely,]]></description>
            <content:encoded><![CDATA[<p><strong>Abstract.</strong> A hands on guide to using PyTorch Lightning. Concretely,
we grab the GPT-2 model from Huggingface and build a lightning module
to train it (more or less from scratch).</p><p>ðŸ˜´ Lazy blog - just a link to the talk's <a target="_blank" href="/assets/files/2021-05-07-deck-795bfc446fe8fcec707c1c4ead2d099b.pdf">ðŸ“‹PDF</a>.</p>]]></content:encoded>
            <category>talk</category>
            <category>nlp</category>
        </item>
        <item>
            <title><![CDATA[âœ¨Talk: Pipeline Model Parallelism]]></title>
            <link>https://aminsaied.github.io/blog/2021/02/12/parallelism</link>
            <guid>/2021/02/12/parallelism</guid>
            <pubDate>Fri, 12 Feb 2021 00:00:00 GMT</pubDate>
            <description><![CDATA[Abstract. Models are getting increasingly large, to the point that]]></description>
            <content:encoded><![CDATA[<p><strong>Abstract.</strong> Models are getting increasingly large, to the point that
they don't always fit on a single device! We discuss some techniques to
partition models over multiple devices, from plain PyTorch to libraries
like deepspeed.</p><p>ðŸ˜´ Lazy blog - just a link to the talk's <a target="_blank" href="/assets/files/2021-02-12-deck-72c8ab0e8dedb0d88d81f51b8b88f308.pdf">ðŸ“‹PDF</a>.</p>]]></content:encoded>
            <category>talk</category>
            <category>nlp</category>
        </item>
        <item>
            <title><![CDATA[âœ¨Talk: GPT-1 and GPT-2 Review]]></title>
            <link>https://aminsaied.github.io/blog/2021/01/15/gpt1-gpt2</link>
            <guid>/2021/01/15/gpt1-gpt2</guid>
            <pubDate>Fri, 15 Jan 2021 00:00:00 GMT</pubDate>
            <description><![CDATA[Abstract. In this talk we'll review the GPT-1 paper]]></description>
            <content:encoded><![CDATA[<p><strong>Abstract.</strong> In this talk we'll review the GPT-1 paper
<a href="https://www.cs.ubc.ca/~amuham01/LING530/papers/radford2018improving.pdf" target="_blank" rel="noopener noreferrer">Improving Language Understanding by Generative Pre-Training - Radford et al</a>.
By way of setting the stage we will give a brief review of the
Transformer architecture.</p><p>Note: We didn't have time to cover GPT-2 in this talk, but some slides on the topic made it into the deck.</p><p>ðŸ˜´ Lazy blog - just a link to the talk's <a target="_blank" href="/assets/files/2021-01-15-deck-926c72d51bf5964cd56b842966c215d1.pdf">ðŸ“‹PDF</a>.</p>]]></content:encoded>
            <category>talk</category>
            <category>nlp</category>
        </item>
        <item>
            <title><![CDATA[âœ¨Talk: Introduction to ðŸ¤—Hugging Face]]></title>
            <link>https://aminsaied.github.io/blog/2020/12/18/intro-to-huggingface</link>
            <guid>/2020/12/18/intro-to-huggingface</guid>
            <pubDate>Fri, 18 Dec 2020 00:00:00 GMT</pubDate>
            <description><![CDATA[Abstract. In this talk we'll review the ðŸ¤—Hugging Face Transformers]]></description>
            <content:encoded><![CDATA[<p><strong>Abstract.</strong> In this talk we'll review the ðŸ¤—Hugging Face Transformers
library. This is an open-source library with the stated goal to "democratize
NLP". We'll briefly review some background, explain what problems Huggingface
is trying to address, and cover some of the tools and techniques they provide.
We will not assume any familiarity with transformers.</p><p>ðŸ˜´ Lazy blog - just a link to the talk's <a target="_blank" href="/assets/files/2020-12-18-deck-5cd1b7aba1eed9f288819581300e8226.pdf">ðŸ“‹PDF</a>.</p>]]></content:encoded>
            <category>talk</category>
            <category>nlp</category>
        </item>
    </channel>
</rss>