---
title: 'âœ¨Talk: GPT-1 and GPT-2 Review'
authors:
  - aminsaied
tags:
  - talk
  - nlp
---

**Abstract.** In this talk we'll review the GPT-1 paper
[Improving Language Understanding by Generative Pre-Training - Radford et al][1].
By way of setting the stage we will give a brief review of the
Transformer architecture.

Note: We didn't have time to cover GPT-2 in this talk, but some slides on the topic made it into the deck.

<!--truncate-->

ðŸ˜´ Lazy blog - just a link to the talk's [ðŸ“‹PDF](2021-01-15-deck.pdf).

[1]: https://www.cs.ubc.ca/~amuham01/LING530/papers/radford2018improving.pdf
[2]: https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf
