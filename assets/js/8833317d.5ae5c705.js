"use strict";(self.webpackChunkaminsaied=self.webpackChunkaminsaied||[]).push([[53],{3905:(n,e,t)=>{t.d(e,{Zo:()=>c,kt:()=>k});var r=t(7294);function a(n,e,t){return e in n?Object.defineProperty(n,e,{value:t,enumerable:!0,configurable:!0,writable:!0}):n[e]=t,n}function o(n,e){var t=Object.keys(n);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(n);e&&(r=r.filter((function(e){return Object.getOwnPropertyDescriptor(n,e).enumerable}))),t.push.apply(t,r)}return t}function i(n){for(var e=1;e<arguments.length;e++){var t=null!=arguments[e]?arguments[e]:{};e%2?o(Object(t),!0).forEach((function(e){a(n,e,t[e])})):Object.getOwnPropertyDescriptors?Object.defineProperties(n,Object.getOwnPropertyDescriptors(t)):o(Object(t)).forEach((function(e){Object.defineProperty(n,e,Object.getOwnPropertyDescriptor(t,e))}))}return n}function s(n,e){if(null==n)return{};var t,r,a=function(n,e){if(null==n)return{};var t,r,a={},o=Object.keys(n);for(r=0;r<o.length;r++)t=o[r],e.indexOf(t)>=0||(a[t]=n[t]);return a}(n,e);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(n);for(r=0;r<o.length;r++)t=o[r],e.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(n,t)&&(a[t]=n[t])}return a}var l=r.createContext({}),d=function(n){var e=r.useContext(l),t=e;return n&&(t="function"==typeof n?n(e):i(i({},e),n)),t},c=function(n){var e=d(n.components);return r.createElement(l.Provider,{value:e},n.children)},p={inlineCode:"code",wrapper:function(n){var e=n.children;return r.createElement(r.Fragment,{},e)}},u=r.forwardRef((function(n,e){var t=n.components,a=n.mdxType,o=n.originalType,l=n.parentName,c=s(n,["components","mdxType","originalType","parentName"]),u=d(t),k=a,_=u["".concat(l,".").concat(k)]||u[k]||p[k]||o;return t?r.createElement(_,i(i({ref:e},c),{},{components:t})):r.createElement(_,i({ref:e},c))}));function k(n,e){var t=arguments,a=e&&e.mdxType;if("string"==typeof n||a){var o=t.length,i=new Array(o);i[0]=u;var s={};for(var l in e)hasOwnProperty.call(e,l)&&(s[l]=e[l]);s.originalType=n,s.mdxType="string"==typeof n?n:a,i[1]=s;for(var d=2;d<o;d++)i[d]=t[d];return r.createElement.apply(null,i)}return r.createElement.apply(null,t)}u.displayName="MDXCreateElement"},6661:(n,e,t)=>{t.r(e),t.d(e,{assets:()=>l,contentTitle:()=>i,default:()=>p,frontMatter:()=>o,metadata:()=>s,toc:()=>d});var r=t(7462),a=(t(7294),t(3905));const o={title:"Distributed Data Parallel (DDP)",description:"Notes and code-snippets on using DDP with PyTorch."},i=void 0,s={unversionedId:"dsref/ml/ddp",id:"dsref/ml/ddp",title:"Distributed Data Parallel (DDP)",description:"Notes and code-snippets on using DDP with PyTorch.",source:"@site/docs/dsref/ml/ddp.md",sourceDirName:"dsref/ml",slug:"/dsref/ml/ddp",permalink:"/docs/dsref/ml/ddp",draft:!1,tags:[],version:"current",frontMatter:{title:"Distributed Data Parallel (DDP)",description:"Notes and code-snippets on using DDP with PyTorch."},sidebar:"dsrefSidebar",previous:{title:"CUDA",permalink:"/docs/dsref/ml/cuda"},next:{title:"Python",permalink:"/docs/category/python"}},l={},d=[{value:"Rough notes",id:"rough-notes",level:2},{value:"Basic example",id:"basic-example",level:2},{value:"Examples: Collective operations",id:"examples-collective-operations",level:2},{value:"<code>all_gather</code>",id:"all_gather",level:3},{value:"<code>gather</code>",id:"gather",level:3},{value:"All Gather a list of tensors",id:"all-gather-a-list-of-tensors",level:3}],c={toc:d};function p(n){let{components:e,...o}=n;return(0,a.kt)("wrapper",(0,r.Z)({},c,o,{components:e,mdxType:"MDXLayout"}),(0,a.kt)("h2",{id:"rough-notes"},"Rough notes"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},"When using DDP it is important to set the seed explicitly, since each process will initialize its own version of the model.")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},"Sketch of PyTorch Lightning DDP:"))),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"num_nodes = 8\ngpus_per_node = 8\nworld_size = num_nodes * gpus_per_node\n\n# start training on each process\nfor node in num_nodes:\n    for gpu in gpus_per_node:\n        init_new_process()\n        set_environment_variables(world_size=world_size, group_rank=node, local_rank=gpu)\n        run_script('python train.py --arg1 val1 ...')\n")),(0,a.kt)("h2",{id:"basic-example"},"Basic example"),(0,a.kt)("p",null,"Modified example from here: ",(0,a.kt)("a",{parentName:"p",href:"https://pytorch.org/tutorials/intermediate/ddp_tutorial.html"},"https://pytorch.org/tutorials/intermediate/ddp_tutorial.html")),(0,a.kt)("p",null,"Note:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"When using 'spawn' method, make sure call is run within ",(0,a.kt)("inlineCode",{parentName:"li"},"if __name__ == '__main__'")," block"),(0,a.kt)("li",{parentName:"ul"},"Couldn't get this to work in jupyter notebook"),(0,a.kt)("li",{parentName:"ul"},"Span up an Azure ML NV12 series (2 x NVIDIA Tesla M60)")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'import os\nimport sys\nimport tempfile\nimport torch\nimport torch.distributed as dist\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.multiprocessing as mp\n\nfrom torch.nn.parallel import DistributedDataParallel as DDP\n\n\nclass ToyModel(nn.Module):\n    def __init__(self):\n        super(ToyModel, self).__init__()\n        self.net1 = nn.Linear(10, 10)\n        self.relu = nn.ReLU()\n        self.net2 = nn.Linear(10, 5)\n\n    def forward(self, x):\n        return self.net2(self.relu(self.net1(x)))\n    \ndef setup(rank, world_size):\n    os.environ["MASTER_ADDR"] = "localhost"\n    os.environ["MASTER_PORT"] = "12355"\n    # initialize the process group\n    dist.init_process_group(\n        "nccl",\n        init_method=\'env://\',\n        rank=rank,\n        world_size=world_size,\n    )\n\ndef cleanup():\n    dist.destroy_process_group()\n    \ndef distribted_run(rank, world_size):\n    print(f"Running on rank {rank}.")\n    setup(rank, world_size)\n\n    # create model and move it to GPU with id rank\n    model = ToyModel().to(rank)\n    ddp_model = DDP(\n        model,\n        device_ids=[rank],\n        output_device=rank,\n    )\n\n    loss_fn = nn.MSELoss()\n    optimizer = optim.SGD(\n        ddp_model.parameters(),\n        lr=0.001,\n    )\n\n    optimizer.zero_grad()\n    outputs = ddp_model(torch.randn(20, 10).to(rank))\n    labels = torch.randn(20, 5).to(rank)\n    loss = loss_fn(outputs, labels)\n    loss.backward()\n    optimizer.step()\n\n    print(f\'Loss on rank {rank}: {loss}\')\n    \n    cleanup()\n    \nif __name__ == \'__main__\':\n    # nb. it is important to run this within if __name__ == \'__main__\' block\n    # since using \'spawn\'\n    world_size = 2\n\n    # The function is called as ``fn(i, *args)``, where ``i`` is\n    # the process index and ``args`` is the passed through tuple\n    # of arguments.\n    mp.spawn(\n        fn=distribted_run,\n        args=(world_size,),  # rank is passed as first arg\n        nprocs=world_size,\n        join=True,  # Perform a blocking join on all processes.\n    )\n')),(0,a.kt)("p",null,"Output:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"Running on rank 0.\nRunning on rank 1.\nLoss on rank 0: 1.3665930032730103\nLoss on rank 1: 1.1837959289550781\n")),(0,a.kt)("h2",{id:"examples-collective-operations"},"Examples: Collective operations"),(0,a.kt)("p",null,"A picture tells a thousand words: ",(0,a.kt)("img",{src:t(5316).Z,width:"1177",height:"1147"})),(0,a.kt)("h3",{id:"all_gather"},(0,a.kt)("inlineCode",{parentName:"h3"},"all_gather")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'def distribted_run(rank, world_size):\n    print(f"Running on rank {rank}.")\n    setup(rank, world_size)\n    \n    x = torch.randn(1, 3).to(rank)\n    print(f"On rank {rank}:", x)\n    \n    gathered_xs = [torch.zeros_like(x) for _ in range(world_size)]\n    dist.all_gather(tensor_list=gathered_xs, tensor=x)\n    print(f"Gathered on rank {rank}:", gathered_xs)\n\n    cleanup()\n')),(0,a.kt)("p",null,"Output"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"Running on rank 1.\nRunning on rank 0.\nOn rank 1: tensor([[-1.4494,  0.5864, -1.4546]], device='cuda:1')\nOn rank 0: tensor([[-0.1952, -0.7890,  0.7067]], device='cuda:0')\nGathered on rank 0: [tensor([[-0.1952, -0.7890,  0.7067]], device='cuda:0'), tensor([[-1.4494,  0.5864, -1.4546]], device='cuda:0')]\nGathered on rank 1: [tensor([[-0.1952, -0.7890,  0.7067]], device='cuda:1'), tensor([[-1.4494,  0.5864, -1.4546]], device='cuda:1')]\n")),(0,a.kt)("h3",{id:"gather"},(0,a.kt)("inlineCode",{parentName:"h3"},"gather")),(0,a.kt)("p",null,(0,a.kt)("strong",{parentName:"p"},"Note")," Gather is not supported with NCCL backend in my testing."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'def distribted_run(rank, world_size):\n    # setup distributed backend\n    os.environ["MASTER_ADDR"] = "localhost"\n    os.environ["MASTER_PORT"] = "12355"\n    # initialize the process group\n    dist.init_process_group(\n        "gloo",\n        init_method=\'env://\',\n        rank=rank,\n        world_size=world_size,\n    )\n\n    print(f"Running on rank {rank}.")\n    \n    x = torch.randn(1, 3).to(rank)\n    print(f"On rank {rank}:", x)\n\n    # set destination rank\n    dst = 0\n    \n    # define gather_list\n    # note: needs to be None on non-dst ranks\n    # note: should have "correct shape" on dst rank\n    gather_list = [torch.zeros_like(x) for _ in range(world_size)] if rank == dst else None\n    \n    dist.gather(tensor=x, dst=dst, gather_list=gather_list)\n    print(f"Gather list on rank {rank}", gather_list)\n\n    cleanup()\n')),(0,a.kt)("p",null,"Output"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"Running on rank 0.\nRunning on rank 1.\nOn rank 0: tensor([[-1.2718, -0.1054, -0.3968]], device='cuda:0')\nOn rank 1: tensor([[-0.3084,  1.3772, -0.4334]], device='cuda:1')\nGather list on rank 1 None\nGather list on rank 0 [tensor([[-1.2718, -0.1054, -0.3968]], device='cuda:0'), tensor([[-0.3084,  1.3772, -0.4334]], device='cuda:0')]\n")),(0,a.kt)("h3",{id:"all-gather-a-list-of-tensors"},"All Gather a list of tensors"),(0,a.kt)("p",null,(0,a.kt)("inlineCode",{parentName:"p"},"all_gather")," operates on tensors. It can be inefficient to iterate over a list of tensors\none at a time and apply all_reduce. Instead we can:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"torch.cat")," the list of tensors into a single tensor"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"torch.distributed.all_reduce")," on this concatenated list of tensors, now a tensor"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"torch.chunk")," is inverse to torch.cat")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"def distribted_run(rank, world_size):\n    setup(rank, world_size)\n    \n    def dprint(string, obj):\n    '''Helper method to print on one rank at a time.'''\n        for i in range(world_size):\n            if rank == i:\n                print(f'Rank {rank}: {string}')\n                print(obj)\n                print()\n            dist.barrier()\n\n    print(f\"Running on rank {rank}.\\n\")\n\n    list_of_tensors = [torch.randn(1, 2).to(rank) for _ in range(3)]\n    n = len(list_of_tensors)\n    dprint(\"List of tensors\", list_of_tensors)\n    \n    cat_list_of_tensors = torch.cat(list_of_tensors, -1)\n    \n    dprint('Concatenated tensor', cat_list_of_tensors)\n    \n    gathered_cat = [torch.zeros_like(cat_list_of_tensors) for _ in range(world_size)]\n    dist.all_gather(tensor_list=gathered_cat, tensor=cat_list_of_tensors)\n    \n    dprint(\"Gathered concatenated\", gathered_cat)\n    \n    chunk_gathered_cat = []\n    for cat_list_of_tensors in gathered_cat:\n        chunk_cat = torch.chunk(cat_list_of_tensors, n, 1)\n        for t in chunk_cat:\n            chunk_gathered_cat.append(t)\n    \n    dprint('Gathered un-concatenated', chunk_gathered_cat)\n    \n    cleanup()\n")),(0,a.kt)("p",null,"Output:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"Running on rank 0.\nRunning on rank 1.\n\nRank 0: List of tensors\n[tensor([[-0.3920, -0.2459]], device='cuda:0'), tensor([[0.3852, 0.7020]], device='cuda:0'), tensor([[2.5578, 1.0345]], device='cuda:0')]\n\nRank 1: List of tensors\n[tensor([[-0.6233, -0.2735]], device='cuda:1'), tensor([[ 1.0148, -0.4607]], device='cuda:1'), tensor([[1.1005, 0.0173]], device='cuda:1')]\n\nRank 0: Concatenated tensor\ntensor([[-0.3920, -0.2459,  0.3852,  0.7020,  2.5578,  1.0345]],\n       device='cuda:0')\n\nRank 1: Concatenated tensor\ntensor([[-0.6233, -0.2735,  1.0148, -0.4607,  1.1005,  0.0173]],\n       device='cuda:1')\n\nRank 0: Gathered concatenated\n[tensor([[-0.3920, -0.2459,  0.3852,  0.7020,  2.5578,  1.0345]],\n       device='cuda:0'), tensor([[-0.6233, -0.2735,  1.0148, -0.4607,  1.1005,  0.0173]],\n       device='cuda:0')]\n\nRank 1: Gathered concatenated\n[tensor([[-0.3920, -0.2459,  0.3852,  0.7020,  2.5578,  1.0345]],\n       device='cuda:1'), tensor([[-0.6233, -0.2735,  1.0148, -0.4607,  1.1005,  0.0173]],\n       device='cuda:1')]\n\nRank 0: Gathered un-concatenated\n[tensor([[-0.3920, -0.2459]], device='cuda:0'), tensor([[0.3852, 0.7020]], device='cuda:0'), tensor([[2.5578, 1.0345]], device='cuda:0'), tensor([[-0.6233, -0.2735]], device='cuda:0'), tensor([[ 1.0148, -0.4607]], device='cuda:0'), tensor([[1.1005, 0.0173]], device='cuda:0')]\n\nRank 1: Gathered un-concatenated\n[tensor([[-0.3920, -0.2459]], device='cuda:1'), tensor([[0.3852, 0.7020]], device='cuda:1'), tensor([[2.5578, 1.0345]], device='cuda:1'), tensor([[-0.6233, -0.2735]], device='cuda:1'), tensor([[ 1.0148, -0.4607]], device='cuda:1'), tensor([[1.1005, 0.0173]], device='cuda:1')]\n")))}p.isMDXComponent=!0},5316:(n,e,t)=>{t.d(e,{Z:()=>r});const r=t.p+"assets/images/ddp-collective-6eb1faffc4905d5b0a3e03cc13e548fc.png"}}]);